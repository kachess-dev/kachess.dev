---
title: AI psychosis is a growing danger. ChatGPT is moving in the wrong direction
  | Amandeep Jutla
date: '2025-10-28T14:00:37+00:00'
source: The Guardian - US
source_url: https://www.theguardian.com/commentisfree/2025/oct/28/ai-psychosis-chatgpt-openai-sam-altman
original_content: |-
  OpenAI’s CEO has announced loosening the platform’s safety restrictions. He seems not to understand how humans are wired

  On 14 October 2025, the CEO of OpenAI made an [extraordinary announcement](https://x.com/sama/status/1978129344598827128).

  “We made ChatGPT pretty restrictive,” it says, “to make sure we were being careful with mental health issues.”

  Amandeep Jutla MD is an associate research scientist in the division of child and adolescent psychiatry at Columbia University and the New York State Psychiatric Institute

   [Continue reading...](https://www.theguardian.com/commentisfree/2025/oct/28/ai-psychosis-chatgpt-openai-sam-altman)
content_checksum: dc5f7b30d491ee5ccdf9708200e49d721817fed121e8d1defc5b9aefec1e42a8
summarized: true
---

On October 14, 2025, OpenAI CEO announced that they were loosening the safety restrictions on ChatGPT, previously designed to be restrictive for mental health considerations. This move has raised concerns among experts, questioning if the platform's leadership understands human psychology. Amandeep Jutla MD, an associate research scientist in child and adolescent psychiatry at Columbia University and the New York State Psychiatric Institute, is among those concerned about the potential implications of this decision. Critics argue that this change could potentially lead to increased dangers, especially in the context of mental health.