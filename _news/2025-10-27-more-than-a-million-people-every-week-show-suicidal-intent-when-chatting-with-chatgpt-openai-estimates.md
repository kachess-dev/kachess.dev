---
title: More than a million people every week show suicidal intent when chatting with
  ChatGPT, OpenAI estimates
date: '2025-10-27T22:26:05+00:00'
source: The Guardian - US
source_url: https://www.theguardian.com/technology/2025/oct/27/chatgpt-suicide-self-harm-openai
original_content: |-
  Finding is one of most direct statements from the tech company on how AI can exacerbate mental health issues

  More than a million ChatGPT users each week send messages that include “explicit indicators of potential suicidal planning or intent”, according to a blogpost published by OpenAI on Monday. The finding, part of an update on how the chatbot handles sensitive conversations, is one of the most direct statements from the artificial intelligence giant on the scale of how AI can exacerbate mental health issues.

  In addition to its estimates on suicidal ideations and related interactions, OpenAI also said that about 0.07 of users active in a given week – about 560,000 of its touted [800m weekly users](https://techcrunch.com/2025/10/06/sam-altman-says-chatgpt-has-hit-800m-weekly-active-users/) – show “possible signs of mental health emergencies related to psychosis or mania”. The post cautioned that these conversations were difficult to detect or measure, and that this was an initial analysis.

   [Continue reading...](https://www.theguardian.com/technology/2025/oct/27/chatgpt-suicide-self-harm-openai)
content_checksum: 2403ff68f17fcebe36b834d69afa0f8e58845dddd4539dc686851ed12605220f
summarized: true
---

OpenAI revealed that over a million weekly users of its chatbot, ChatGPT, send messages indicating potential suicidal planning or intent, highlighting AI's potential to amplify mental health issues. Additionally, about 0.07% of active users, around 560,000 out of the 800 million weekly users, demonstrate possible signs of mental health emergencies related to psychosis or mania. OpenAI noted the difficulty in detecting and measuring these conversations and stated that these findings are part of an initial analysis.